{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f29a7c-dfd9-4fa5-a317-3b1ada35fa4b",
   "metadata": {},
   "source": [
    "目前的绘图逻辑从上到下是\n",
    "1.prior和post；\n",
    "2.parameter和hydrograph\n",
    "3.parameter的ensemble version和 mean-std version\n",
    "4.hydrograph的frame和anaimation\n",
    "，然后中间可能有不同station的hydrograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ddb26d-98f5-4af9-87bf-531d980db646",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m current_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisualize_improved.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(current_file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_yaml\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mifc_usgs_fileorder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_usgs_mapping_from_path\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 全局 matplotlib 设置\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import hydroeval as he\n",
    "import copy\n",
    "current_file = 'visualize_improved.ipynb'\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(current_file), '..', '..')))\n",
    "from utils import process_yaml\n",
    "from ifc_usgs_fileorder import load_usgs_mapping_from_path\n",
    "\n",
    "\n",
    "# 全局 matplotlib 设置\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4faa50ca-e91d-4653-89db-0b029472e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 评价指标函数 =====================\n",
    "def kge_metric(obs, sim):\n",
    "    \"\"\"计算模拟与观测数据的 NSE 指标（可改为真实KGE计算）\"\"\"\n",
    "    return he.evaluator(he.nse, sim[obs > 0], obs[obs > 0])\n",
    "\n",
    "def peak_relative_diff(obs, sim):\n",
    "    \"\"\"计算模拟与观测峰值的相对差异\"\"\"\n",
    "    return (np.max(sim) - np.max(obs)) / np.max(obs)\n",
    "\n",
    "def peak_timing_diff(obs, sim):\n",
    "    \"\"\"计算模拟与观测达到峰值时刻的索引差\"\"\"\n",
    "    return np.argmax(sim) - np.argmax(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1467c3a4-4ae6-4cea-9161-21dd159bf7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 工具函数：清空并创建文件夹 ------------------\n",
    "def clear_and_create_dir(dir_path):\n",
    "    \"\"\"若目录存在，则清空（删除整个目录），再重新创建该目录\"\"\"\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "\n",
    "# ===================== 动画帧绘制函数 =====================\n",
    "def draw_animation_frame(iter_idx, ensemble_sim, station_idx, time_axis, measured_data, station_label):\n",
    "    \"\"\"\n",
    "    绘制单个动画帧。\n",
    "\n",
    "    参数:\n",
    "      iter_idx: 当前同化迭代编号（格式化为两位数）。\n",
    "      ensemble_sim: 模型模拟粒子数据，形状为 (ensemble_size, time_steps, num_stations)。\n",
    "      station_idx: 当前绘制的观测站索引（直接显示，无格式宽度）。\n",
    "      time_axis: 时间序列 (pandas DatetimeIndex)。\n",
    "      measured_data: 观测数据数组，形状为 (time_steps, num_stations)。\n",
    "      station_label: 站点名称，用于图标题显示（此处我们希望显示 gauge id）。\n",
    "    \"\"\"\n",
    "    plt.clf()  # 清空当前图形\n",
    "    station_ensemble = ensemble_sim[:, :, station_idx]\n",
    "    median_sim = np.median(station_ensemble, axis=0)\n",
    "    obs_series = measured_data[:, station_idx]\n",
    "\n",
    "    plt.plot(time_axis, median_sim, 'b-', label='Particle median')\n",
    "    plt.fill_between(time_axis,\n",
    "                     np.percentile(station_ensemble, 5, axis=0),\n",
    "                     np.percentile(station_ensemble, 95, axis=0),\n",
    "                     color='blue', alpha=0.3)\n",
    "    plt.plot(time_axis, obs_series, 'k--', label='Observed')\n",
    "\n",
    "    try:\n",
    "        kge_val = kge_metric(obs_series, median_sim)\n",
    "        pr_diff = peak_relative_diff(obs_series, median_sim)\n",
    "        pt_diff = peak_timing_diff(obs_series, median_sim)\n",
    "        print(f\"Iteration {iter_idx:02d}, Gauge {station_label}: KGE={kge_val}, PeakDiff={pr_diff}, PeakTiming={pt_diff}\")\n",
    "    except Exception:\n",
    "        print(f\"Iteration {iter_idx:02d}, Gauge {station_label}: Metric calculation failed.\")\n",
    "\n",
    "    plt.title(f'EKI iteration {iter_idx:02d} - Gauge {station_label}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Discharge (m^3/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "# ===================== 数据加载辅助函数 =====================\n",
    "def load_ensemble(assimilation_phase, iter_idx):\n",
    "    \"\"\"\n",
    "    根据同化阶段和迭代编号加载模拟粒子数据。\n",
    "\n",
    "    参数:\n",
    "      assimilation_phase: 字符串 'post' 或 'prior'\n",
    "      iter_idx: 当前迭代编号（对于 post，iter_idx==0 使用先验文件）\n",
    "    返回:\n",
    "      模型模拟粒子数据数组。\n",
    "    \"\"\"\n",
    "    if assimilation_phase == 'post':\n",
    "        if iter_idx == 0:\n",
    "            file_path = 'npy/0_prior_particles.npy'\n",
    "        else:\n",
    "            file_path = f'npy/{iter_idx - 1}_post_particles.npy'\n",
    "    elif assimilation_phase == 'prior':\n",
    "        file_path = f'npy/{iter_idx}_prior_particles.npy'\n",
    "    else:\n",
    "        raise ValueError(\"assimilation_phase must be 'post' or 'prior'\")\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return np.load(f)\n",
    "\n",
    "# ===================== 动画生成函数 =====================\n",
    "def generate_hydrograph_animation(num_iters, station_indices, station_names, measured_data, time_axis, assimilation_phase, base_output_dir):\n",
    "    \"\"\"\n",
    "    生成并保存 hydrograph 动画 GIF。\n",
    "\n",
    "    参数:\n",
    "      num_iters: 同化迭代步数（post: num_iters+1；prior: num_iters）\n",
    "      station_indices: 要绘制的站点在观测数据中的列索引列表\n",
    "      station_names: 对应的站点名称列表（通常与 desired_usgs_ids 一致，即 gauge id）\n",
    "      measured_data: 观测数据数组 (time_steps, num_stations)\n",
    "      time_axis: 时间序列 (pandas DatetimeIndex)\n",
    "      assimilation_phase: 'post' 或 'prior'\n",
    "      base_output_dir: 顶层输出文件夹（例如 visualization）\n",
    "    \"\"\"\n",
    "    hydrograph_frames_dir = os.path.join(base_output_dir, assimilation_phase, \"hydrograph\", \"frames\")\n",
    "    hydrograph_anim_dir = os.path.join(base_output_dir, assimilation_phase, \"hydrograph\", \"animation\")\n",
    "    clear_and_create_dir(hydrograph_frames_dir)\n",
    "    clear_and_create_dir(hydrograph_anim_dir)\n",
    "    \n",
    "    iter_range = range(num_iters + 1) if assimilation_phase == 'post' else range(num_iters)\n",
    "    \n",
    "    # 遍历传入的站点索引及对应的站点名称（gauge id）\n",
    "    for i, station_idx in enumerate(station_indices):\n",
    "        station_label = station_names[i]\n",
    "        frame_imgs = []\n",
    "        for iter_idx in iter_range:\n",
    "            plt.clf()\n",
    "            ensemble_sim = load_ensemble(assimilation_phase, iter_idx)\n",
    "            y_limits = [0, 3 * np.max(measured_data[:, station_idx])]\n",
    "            draw_animation_frame(iter_idx, ensemble_sim, station_idx, time_axis, measured_data,\n",
    "                                 station_label=station_label)\n",
    "            plt.ylim(*y_limits)\n",
    "            # 文件名：iter_XX_station_Y_hydrograph.png（iteration 保留两位，station 不填充）\n",
    "            frame_filepath = os.path.join(hydrograph_frames_dir, f\"iter_{iter_idx:02d}_gauge_{station_label}_hydrograph.png\")\n",
    "            plt.savefig(frame_filepath)\n",
    "            frame_imgs.append(Image.open(frame_filepath))\n",
    "        gif_filepath = os.path.join(hydrograph_anim_dir, f\"gauge_{station_label}_hydrograph_animation.gif\")\n",
    "        frame_imgs[0].save(gif_filepath, save_all=True, append_images=frame_imgs[1:], duration=1000, loop=0)\n",
    "        print(f\"Animation saved to {gif_filepath}\")\n",
    "\n",
    "# ===================== 参数演变绘图函数 =====================\n",
    "def plot_parameter_evolution(param_array, active_param_indices, param_labels, param_ranges, assimilation_phase, base_output_dir, iter_range):\n",
    "    \"\"\"\n",
    "    绘制参数演变图，分别保存 ensemble 版本和 mean_std 版本。\n",
    "\n",
    "    参数:\n",
    "      param_array: 参数粒子数据数组，形状 (num_iters, num_active_params, num_stations, particle_dim)\n",
    "      active_param_indices: 原始参数列表中参与同化的参数索引列表\n",
    "      param_labels: 参数名称列表\n",
    "      param_ranges: 参数取值范围列表\n",
    "      assimilation_phase: 'post' 或 'prior'\n",
    "      base_output_dir: 顶层输出文件夹（例如 visualization）\n",
    "      iter_range: 迭代编号数组\n",
    "    \"\"\"\n",
    "    param_ensemble_dir = os.path.join(base_output_dir, assimilation_phase, \"parameter\", \"ensemble\")\n",
    "    param_mean_std_dir = os.path.join(base_output_dir, assimilation_phase, \"parameter\", \"mean_std\")\n",
    "    clear_and_create_dir(param_ensemble_dir)\n",
    "    clear_and_create_dir(param_mean_std_dir)\n",
    "    \n",
    "    num_iters = len(iter_range)\n",
    "    num_stations = param_array.shape[2]\n",
    "    \n",
    "    # Ensemble 版本：保存所有粒子的轨迹\n",
    "    for idx_active, orig_idx in enumerate(active_param_indices):\n",
    "        for station_idx in range(num_stations):\n",
    "            plt.figure()\n",
    "            plt.plot(iter_range, param_array[:, idx_active, station_idx, :])\n",
    "            plt.ylabel(param_labels[orig_idx])\n",
    "            plt.xlabel('EKI Iterations')\n",
    "            plt.ylim(*param_ranges[orig_idx])\n",
    "            # 文件名：parameter_X_station_Y_ensemble.png\n",
    "            out_path = os.path.join(param_ensemble_dir, f\"parameter_{orig_idx}_station_{station_idx}_ensemble.png\")\n",
    "            plt.savefig(out_path)\n",
    "            plt.close()\n",
    "            print(f\"Saved parameter ensemble plot {out_path}\")\n",
    "    \n",
    "    # Mean-Std 版本：均值及标准差统计图\n",
    "    for idx_active, orig_idx in enumerate(active_param_indices):\n",
    "        for station_idx in range(num_stations):\n",
    "            plt.figure()\n",
    "            param_mean = np.mean(param_array[:, idx_active, station_idx, :], axis=1)\n",
    "            param_std = np.std(param_array[:, idx_active, station_idx, :], axis=1)\n",
    "            plt.plot(iter_range, param_mean, 'k-', lw=2, label='Mean')\n",
    "            plt.fill_between(iter_range, param_mean - param_std, param_mean + param_std,\n",
    "                             color='gray', alpha=0.3, label='Mean ± Std')\n",
    "            plt.ylabel(param_labels[orig_idx])\n",
    "            plt.xlabel('EKI Iterations')\n",
    "            plt.ylim(*param_ranges[orig_idx])\n",
    "            # 文件名：parameter_X_station_Y_mean_std.png\n",
    "            out_path = os.path.join(param_mean_std_dir, f\"parameter_{orig_idx}_station_{station_idx}_mean_std.png\")\n",
    "            plt.savefig(out_path)\n",
    "            plt.close()\n",
    "            print(f\"Saved parameter mean-std plot {out_path}\")\n",
    "\n",
    "# ===================== 事件统计绘图函数 =====================\n",
    "def plot_event_statistics(assimilation_phase, base_output_dir):\n",
    "    \"\"\"\n",
    "    计算并绘制事件统计图，将三个统计量（峰值、均值、标准差）转移到图形中保存。\n",
    "\n",
    "    这里假设从 CSV 文件中读取观测数据用于计算事件统计量，\n",
    "    实际项目中可替换为更复杂的事件检测算法。\n",
    "    \"\"\"\n",
    "    # 读取观测数据（假设同一文件）\n",
    "    measured_data = np.genfromtxt(\"csv/meas_mean.csv\", delimiter=',', skip_header=1)\n",
    "    measured_data[measured_data == 0] = np.nan\n",
    "\n",
    "    # 对每个站点计算统计量（这里简单采用整个时间序列的统计量作为示例）\n",
    "    event_peaks = np.nanmax(measured_data, axis=0)\n",
    "    event_means = np.nanmean(measured_data, axis=0)\n",
    "    event_stds  = np.nanstd(measured_data, axis=0)\n",
    "\n",
    "    event_stats_dir = os.path.join(base_output_dir, assimilation_phase, \"event_statistics\")\n",
    "    clear_and_create_dir(event_stats_dir)\n",
    "\n",
    "    stations = np.arange(measured_data.shape[1])\n",
    "    plt.figure()\n",
    "    plt.plot(stations, event_peaks, 'r-o', label=\"Peak\")\n",
    "    plt.xlabel(\"Station\")\n",
    "    plt.ylabel(\"Peak Value\")\n",
    "    plt.title(f\"Event Peak Values ({assimilation_phase})\")\n",
    "    plt.legend()\n",
    "    out_path = os.path.join(event_stats_dir, \"event_peak.png\")\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved event peak plot {out_path}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(stations, event_means, 'g-o', label=\"Mean\")\n",
    "    plt.xlabel(\"Station\")\n",
    "    plt.ylabel(\"Mean Value\")\n",
    "    plt.title(f\"Event Mean Values ({assimilation_phase})\")\n",
    "    plt.legend()\n",
    "    out_path = os.path.join(event_stats_dir, \"event_mean.png\")\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved event mean plot {out_path}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(stations, event_stds, 'b-o', label=\"Std\")\n",
    "    plt.xlabel(\"Station\")\n",
    "    plt.ylabel(\"Standard Deviation\")\n",
    "    plt.title(f\"Event Standard Deviation ({assimilation_phase})\")\n",
    "    plt.legend()\n",
    "    out_path = os.path.join(event_stats_dir, \"event_std.png\")\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved event std plot {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746a2725-dbaa-4afc-9ec3-8b758376003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5527/2667266326.py:9: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_axis = pd.date_range(start=start_time_str, end=end_time_str, freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 00, Gauge 5570910: KGE=[-4.28385832], PeakDiff=-0.2528212363524527, PeakTiming=1\n",
      "Iteration 01, Gauge 5570910: KGE=[-11.45155087], PeakDiff=2.353718283868983, PeakTiming=4\n",
      "Iteration 02, Gauge 5570910: KGE=[-7.28569755], PeakDiff=0.9784061202521912, PeakTiming=6\n",
      "Iteration 03, Gauge 5570910: KGE=[-7.62073893], PeakDiff=1.1082250499769337, PeakTiming=5\n",
      "Iteration 04, Gauge 5570910: KGE=[-6.8218508], PeakDiff=0.7888858988159311, PeakTiming=6\n",
      "Iteration 05, Gauge 5570910: KGE=[-6.90565835], PeakDiff=0.8242807165923419, PeakTiming=6\n",
      "Iteration 06, Gauge 5570910: KGE=[-6.53182793], PeakDiff=0.6635944948485315, PeakTiming=6\n",
      "Iteration 07, Gauge 5570910: KGE=[-6.62273629], PeakDiff=0.703463017069045, PeakTiming=6\n",
      "Iteration 08, Gauge 5570910: KGE=[-6.43504462], PeakDiff=0.6207488851299401, PeakTiming=6\n",
      "Iteration 09, Gauge 5570910: KGE=[-6.58453504], PeakDiff=0.6867868675995694, PeakTiming=6\n",
      "Iteration 10, Gauge 5570910: KGE=[-6.39710911], PeakDiff=0.6044391050284484, PeakTiming=7\n",
      "Animation saved to visualization/post/hydrograph/animation/gauge_5570910_hydrograph_animation.gif\n",
      "Saved parameter ensemble plot visualization/post/parameter/ensemble/parameter_0_station_0_ensemble.png\n",
      "Saved parameter mean-std plot visualization/post/parameter/mean_std/parameter_0_station_0_mean_std.png\n",
      "Saved event peak plot visualization/post/event_statistics/event_peak.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5527/1881629371.py:180: RuntimeWarning: All-NaN slice encountered\n",
      "  event_peaks = np.nanmax(measured_data, axis=0)\n",
      "/tmp/ipykernel_5527/1881629371.py:181: RuntimeWarning: Mean of empty slice\n",
      "  event_means = np.nanmean(measured_data, axis=0)\n",
      "/home/zli333/virtenvs/Hydro_cuda/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved event mean plot visualization/post/event_statistics/event_mean.png\n",
      "Saved event std plot visualization/post/event_statistics/event_std.png\n",
      "Iteration 00, Gauge 5570910: KGE=[-4.28385832], PeakDiff=-0.2528212363524527, PeakTiming=1\n",
      "Iteration 01, Gauge 5570910: KGE=[-11.45155087], PeakDiff=2.353718283868983, PeakTiming=4\n",
      "Iteration 02, Gauge 5570910: KGE=[-7.28569755], PeakDiff=0.9784061202521912, PeakTiming=6\n",
      "Iteration 03, Gauge 5570910: KGE=[-7.62073893], PeakDiff=1.1082250499769337, PeakTiming=5\n",
      "Iteration 04, Gauge 5570910: KGE=[-6.8218508], PeakDiff=0.7888858988159311, PeakTiming=6\n",
      "Iteration 05, Gauge 5570910: KGE=[-6.90565835], PeakDiff=0.8242807165923419, PeakTiming=6\n",
      "Iteration 06, Gauge 5570910: KGE=[-6.53182793], PeakDiff=0.6635944948485315, PeakTiming=6\n",
      "Iteration 07, Gauge 5570910: KGE=[-6.62273629], PeakDiff=0.703463017069045, PeakTiming=6\n",
      "Iteration 08, Gauge 5570910: KGE=[-6.43504462], PeakDiff=0.6207488851299401, PeakTiming=6\n",
      "Iteration 09, Gauge 5570910: KGE=[-6.58453504], PeakDiff=0.6867868675995694, PeakTiming=6\n",
      "Animation saved to visualization/prior/hydrograph/animation/gauge_5570910_hydrograph_animation.gif\n",
      "Saved parameter ensemble plot visualization/prior/parameter/ensemble/parameter_0_station_0_ensemble.png\n",
      "Saved parameter mean-std plot visualization/prior/parameter/mean_std/parameter_0_station_0_mean_std.png\n",
      "Saved event peak plot visualization/prior/event_statistics/event_peak.png\n",
      "Saved event mean plot visualization/prior/event_statistics/event_mean.png\n",
      "Saved event std plot visualization/prior/event_statistics/event_std.png\n",
      "Visualization complete.\n"
     ]
    }
   ],
   "source": [
    "# ===================== 主流程 =====================\n",
    "def main_visualization():\n",
    "    base_output_dir = \"visualization\"\n",
    "    assimilation_phases = ['prior', 'post']\n",
    "    \n",
    "    test_dict = process_yaml(\"test_config.j2\")\n",
    "    start_time_str = test_dict[\"time_start\"]\n",
    "    end_time_str = test_dict[\"time_end\"]\n",
    "    time_axis = pd.date_range(start=start_time_str, end=end_time_str, freq='H')\n",
    "\n",
    "    num_assimilation_steps = test_dict[\"steps\"]\n",
    "    max_station_count = 5  # 默认值，当 desired_usgs_ids 未找到时使用\n",
    "\n",
    "    # 读取 desired_usgs_ids（即 gauge id），确保为列表格式\n",
    "    desired_usgs_ids = test_dict.get(\"meas_usgs\", [])\n",
    "    if isinstance(desired_usgs_ids, str):\n",
    "        desired_usgs_ids = [desired_usgs_ids]\n",
    "        \n",
    "    # 读取 USGS 映射关系（调整路径根据实际情况）\n",
    "    usgs_2_id, id_2_usgs, file_order = load_usgs_mapping_from_path(\"../../\" + test_dict[\"usgs_csv\"])\n",
    "    \n",
    "    # 根据 desired_usgs_ids 计算绘图所用的站点索引和 gauge 名称\n",
    "    plot_station_indices = []\n",
    "    plot_station_names = []\n",
    "    for usgs in desired_usgs_ids:\n",
    "        link_id = usgs_2_id.get(usgs)\n",
    "        if link_id is None:\n",
    "            print(f\"Warning: USGS ID {usgs} not found in mapping.\")\n",
    "            continue\n",
    "        idx_arr = np.where(file_order == link_id)[0]\n",
    "        if idx_arr.size > 0:\n",
    "            plot_station_indices.append(idx_arr[0])\n",
    "            plot_station_names.append(usgs)  # 使用 USGS ID 作为 gauge id 名称\n",
    "        else:\n",
    "            print(f\"Warning: Link id {link_id} for USGS {usgs} not found in file_order.\")\n",
    "    if not plot_station_indices:\n",
    "        print(\"No desired station indices found, using default range.\")\n",
    "        plot_station_indices = list(range(max_station_count))\n",
    "        plot_station_names = [str(i) for i in range(max_station_count)]\n",
    "    \n",
    "    observed_data = np.genfromtxt(\"csv/meas_mean.csv\", delimiter=',', skip_header=1)\n",
    "    observed_data_clean = observed_data.copy()\n",
    "    observed_data[observed_data == 0] = np.nan\n",
    "\n",
    "    # 参数设置: 对已经提取的数据进行“取名”和“限制显示范围”\n",
    "    param_labels = [\"$Cr$\"]\n",
    "    param_ranges = [[0.00, 1.0]]\n",
    "    active_param_indices = [0]\n",
    "\n",
    "    # -------------------- 后验 (post) 部分 --------------------\n",
    "    post_param_list = []\n",
    "    for i in range(num_assimilation_steps + 1):\n",
    "        if i > 0:\n",
    "            file_path = f'npy/{i-1}_post_params_particles.npy'\n",
    "        else:\n",
    "            file_path = 'npy/0_prior_params_particles.npy'\n",
    "        with open(file_path, 'rb') as f:\n",
    "            post_param_list.append(np.load(f))\n",
    "    post_param_array = np.stack(post_param_list, axis=0)\n",
    "    post_param_array = post_param_array.reshape(num_assimilation_steps + 1,\n",
    "                                                 len(active_param_indices),\n",
    "                                                 -1,\n",
    "                                                 post_param_array.shape[-1])\n",
    "    iter_range_post = np.arange(0, num_assimilation_steps + 1)\n",
    "    \n",
    "    # 调用时，将 station_indices 和 station_names 一并传入\n",
    "    generate_hydrograph_animation(num_assimilation_steps, plot_station_indices, plot_station_names,\n",
    "                                  observed_data_clean, time_axis,\n",
    "                                  assimilation_phase='post', base_output_dir=base_output_dir)\n",
    "    plot_parameter_evolution(post_param_array, active_param_indices, param_labels, param_ranges,\n",
    "                             assimilation_phase='post', base_output_dir=base_output_dir, iter_range=iter_range_post)\n",
    "    plot_event_statistics('post', base_output_dir)\n",
    "\n",
    "    # -------------------- 先验 (prior) 部分 --------------------\n",
    "    prior_param_list = []\n",
    "    for i in range(num_assimilation_steps):\n",
    "        file_path = f'npy/{i}_prior_params_particles.npy'\n",
    "        with open(file_path, 'rb') as f:\n",
    "            prior_param_list.append(np.load(f))\n",
    "    prior_param_array = np.stack(prior_param_list, axis=0)\n",
    "    prior_param_array = prior_param_array.reshape(num_assimilation_steps,\n",
    "                                                   len(active_param_indices),\n",
    "                                                   -1,\n",
    "                                                   prior_param_array.shape[-1])\n",
    "    iter_range_prior = np.arange(0, num_assimilation_steps)\n",
    "    generate_hydrograph_animation(num_assimilation_steps, plot_station_indices, plot_station_names,\n",
    "                                  observed_data_clean, time_axis,\n",
    "                                  assimilation_phase='prior', base_output_dir=base_output_dir)\n",
    "    plot_parameter_evolution(prior_param_array, active_param_indices, param_labels, param_ranges,\n",
    "                             assimilation_phase='prior', base_output_dir=base_output_dir, iter_range=iter_range_prior)\n",
    "    plot_event_statistics('prior', base_output_dir)\n",
    "    \n",
    "    plt.close('all')\n",
    "    print(\"Visualization complete.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_visualization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca9759-0614-4ef4-8a7c-d1f92afb4ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hydro_cuda",
   "language": "python",
   "name": "hydro_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
